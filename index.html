<!DOCTYPE html>
<html>

<head>

	<!-- Basic -->
	<meta charset="utf-8">
	<title>CARLOS EDUARDO CANCINO-CHACÓN</title>
	<meta name="keywords" content="CARLOS EDUARDO CANCINO-CHACÓN" />
	<meta name="description" content=" CARLOS EDUARDO CANCINO-CHACÓN">
	<meta name="author" content="CARLOS EDUARDO CANCINO-CHACÓN">

	<!-- Mobile Metas -->
	<meta name="viewport" content="width=device-width, initial-scale=1.0">

	<!-- Web Fonts  -->
	<link href="http://fonts.googleapis.com/css?family=Open+Sans:300,400,600,700,800%7CShadows+Into+Light"
		rel="stylesheet" type="text/css">

	<!-- Vendor CSS -->
	<link rel="stylesheet" href="vendor/bootstrap/bootstrap.css">
	<link rel="stylesheet" href="vendor/fontawesome/css/font-awesome.css">
	<link rel="stylesheet" href="vendor/owlcarousel/owl.carousel.min.css" media="screen">
	<link rel="stylesheet" href="vendor/owlcarousel/owl.theme.default.min.css" media="screen">
	<link rel="stylesheet" href="vendor/magnific-popup/magnific-popup.css" media="screen">

	<!-- Theme CSS -->
	<link rel="stylesheet" href="css/theme.css">
	<link rel="stylesheet" href="css/theme-elements.css">
	<link rel="stylesheet" href="css/theme-blog.css">
	<link rel="stylesheet" href="css/theme-shop.css">
	<link rel="stylesheet" href="css/theme-animate.css">

	<!-- Current Page CSS -->
	<link rel="stylesheet" href="vendor/rs-plugin/css/settings.css" media="screen">
	<link rel="stylesheet" href="vendor/circle-flip-slideshow/css/component.css" media="screen">

	<!-- Skin CSS -->
	<link rel="stylesheet" href="css/skins/default.css">

	<!-- Theme Custom CSS -->
	<link rel="stylesheet" href="css/custom.css">

	<!-- Head Libs -->
	<script src="vendor/modernizr/modernizr.js"></script>

	<!--[if IE]>
	    <link rel="stylesheet" href="css/ie.css">
	<![endif]-->

	<!--[if lte IE 8]>
	    <script src="vendor/respond/respond.js"></script>
	    <script src="vendor/excanvas/excanvas.js"></script>
	<![endif]-->

</head>

<body class="one-page" data-target=".single-menu" data-spy="scroll" data-offset="200"
	style=" background-image: url(bg.jpg); background-position:bottom left; background-size:cover; background-attachment:fixed;">

	<div class="body">
		<header id="header" class="narrow"
			data-plugin-options='{"alwaysStickyEnabled": true, "stickyEnabled": true, "stickyWithGap": false, "stickyChangeLogoSize": false}'>
			<div class="container">

				<button class="btn btn-responsive-nav btn-inverse" data-toggle="collapse"
					data-target=".nav-main-collapse">
					<i class="fa fa-bars"></i>
				</button>
			</div>
			<div class="navbar-collapse nav-main-collapse collapse">
				<div class="container">

					<nav class="nav-main">
						<ul class="nav nav-pills nav-main" id="mainMenu">
							<li>
								<a data-hash href="#home">RESEARCH INTERESTS</a>
							</li>
							<li>
								<a data-hash href="#cv">CV</a>
							</li>

							<li>
								<a data-hash href="#publications">publications</a>

							</li>
							<!-- <li>
								<a data-hash href="#music1">Music</a>

							</li> -->
							<li>
								<a
									href="https://www.jku.at/en/institute-of-computational-perception/about-us/people/carlos-eduardo-cancino-chacon/">JKU
									website</a>
							</li>
							<!-- <li>
				     <a href="https://blog.carloscancinochacon.com">Blog</a>
				     </li> -->


						</ul>
					</nav>
				</div>
			</div>
		</header>

		<div role="main" class="main" id="home">




			<div class="container">


			</div>

			<div class="container">
				<div class="row" id="features">
					<br><br><br>
					<div class="col-md-6">

						<h2 data-appear-animation="fadeInLeft">CARLOS EDUARDO <strong> CANCINO-CHACÓN</strong></h2><br>
						<!-- <p><strong>Assistant Professor</strong></p> -->
						<!-- <h5>Assistant Professor</h5><br> -->
						<div class="row">
							<div class="col-sm-10">
								<span style="font-size:15px; font-weight:600;">
									Senior Researcher<br>
									Institute of Computational Perception<br>
									Johannes Kepler University Linz<br>
									Wiesingerstraße 4, 2. Floor, Room 250<br>
									1010 Vienna, Austria <br>
									<!-- Freyung 6/6<br>
					     1010 Vienna, Austria<br> -->
								</span>
								<p>

									<strong>Email:</strong> carlos.cancino_chacon@jku.at

								</p>
								<br><br>


								<h3 data-appear-animation="fadeInLeft"><strong>RESEARCH INTERESTS</strong></h3>

								<p>
									Computational Music Rehearsal Analysis<br>
									Computational Models of Expressive Music Performance<br>
									Human-Computer Interaction in Music<br>
									Cognitively-plausible Computational Models of Music Analysis<br>
									Symbolic Music Processing<br>
									Music Information Retrieval<br>
									Machine Learning (Deep Learning, Probabilistic Graphical Models)<br>
								</p>



							</div>


						</div>
					</div>
					<div class="col-md-4">


						<img data-appear-animation="fadeInRight" class="img-responsive" src="carloscancino.png">


					</div>
				</div>
				<hr class="tall" id="cv" />
				<br>
				<div class="row" id="features">
					<div class="col-md-9">

						<h3 data-appear-animation="fadeInLeft"><strong>CURRICULUM</strong> VITAE</h3>
						<h4 data-appear-animation="fadeInLeft">EDUCATION <strong></strong></h4>

						<div class="row">


							<div class="col-sm-2"><span style="font-size:19px;color:#2fd6f7;">2014 - 2018</span> </div>
							<div class="col-sm-10"> <strong>Doctoral degree in Computer Science, <br>Johannes Kepler
									University of Linz, Austria.</strong><br>
								Supervisor: Gerhard Widmer<br>
								Co-supervisor: Maarten Grachten<br><br></div>


							<div class="col-sm-2"><span style="font-size:19px;color:#2fd6f7;">2011 - 2014</span> </div>
							<div class="col-sm-10"> <strong>Master's degree in Electrical Engineering and Audio
									Engineering,<br> Graz University of Technology/University of Music and Performing
									Arts Graz, Austria.</strong> <br>

								Supervisor: Franz Pernkopf<br><br>

							</div>


							<div class="col-sm-2"><span style="font-size:19px;color:#2fd6f7;">2005 - 2011</span> </div>
							<div class="col-sm-10"> <strong>Undergraduate degree in Physics, <br> National Autonomous
									University of Mexico, Mexico City, Mexico.</strong> <br>

								Supervisor: Marcos Ley Koo.<br><br>

							</div>


							<div class="col-sm-2"><span style="font-size:19px;color:#2fd6f7;">1999 - 2011</span> </div>
							<div class="col-sm-10"> <strong>Undergraduate degree in Piano Performance,
									<br> National Conservatory of Music, Mexico City, Mexico.</strong>
								<br>Supervisor: Héctor Alfonso Rojas Ramírez.
							</div>

						</div>
					</div>
				</div>

				<hr class="tall" id="research" />
				<div class="row">
					<div class="col-md-9">
						<h4 data-appear-animation="fadeInLeft">RESEARCH EXPERIENCE<strong> </strong></h4>

						<div class="row">
							<div class="col-sm-2"><span style="font-size:19px;color:#2fd6f7;">2025 - present<span
										style="font-size:15px;"></span> </span> </div>
							<div class="col-sm-10"> <strong>Institute of Computational Perception<br>
									Johannes Kepler University Linz, Austria</strong><br>
								Senior Researcher<br><br></div>

							<div class="col-sm-2"><span style="font-size:19px;color:#2fd6f7;">2020 - 2025<span
										style="font-size:15px;"></span> </span> </div>
							<div class="col-sm-10"> <strong>Institute of Computational Perception<br>
									Johannes Kepler University Linz, Austria</strong><br>
								Assistant Professor<br><br></div>

							<div class="col-sm-2"><span style="font-size:19px;color:#2fd6f7;">2020 - 2021<span
										style="font-size:15px;"></span> </span> </div>
							<div class="col-sm-10"> <strong>RITMO Centre for Interdisciplinary Studies in Rhythm, Time
									and Motion<br>
									University of Oslo, Norway</strong><br>
								Guest Researcher<br><br></div>

							<div class="col-sm-2"><span style="font-size:19px;color:#2fd6f7;">2018 - 2020 </span>
								</span> </div>
							<div class="col-sm-10"> <strong>Austrian Research Institute for Artificial Intelligence,
									Vienna, Austria<br>
									Intelligent Music Processing and Machine Learning Group</strong><br>
								Posdoctoral Researcher<br><br></div>

							<div class="col-sm-2"><span style="font-size:19px;color:#2fd6f7;">2014 - 2018 </span> </div>
							<div class="col-sm-10"> <strong>Austrian Research Institute for Artificial Intelligence,
									Vienna, Austria<br>
									Intelligent Music Processing and Machine Learning Group</strong><br>
								Predoctoral Researcher<br><br></div>

						</div>
					</div>
				</div>

				<div class="row" id="grants">
					<div class="col-md-9">
						<br><br>
						<h4 data-appear-animation="fadeInLeft">GRANTS<strong> </strong></h4>

						<div class="row">
							<div class="col-sm-2"><span style="font-size:19px;color:#2fd6f7;">2025 - 2029</span> </div>
							<div class="col-sm-10"> <strong>AURA: Augmenting musical interaction via Embodied Virtual
									Avatars</strong><br>
								<a href=https://weave-research.net>Weave</a>: <a
									href=https://research.ugent.be/web/result/project/5349a4a3-bb8e-11ef-aed6-33a67d5acda9/details/en>Research
									Foundation--Flanders (FWO)</a> and
								<a href=https://www.fwf.ac.at/en/research-radar/10.55776/PIN1347924>Austrian Science
									Fund (FWF)</a> <br>
								Principal Investigator (FWO-leading agency): Pieter Jan Maes<br>
								Principal Investigator (FWF): Carlos Cancino-Chacón<br>
								FWF share <strong>€264,679.00</strong> (total Weave project budjet: €826,979.00)<br>
								</a>
							</div>
						</div>
						<br><br>
						<div class="row">
							<div class="col-sm-2"><span style="font-size:19px;color:#2fd6f7;">2024 - 2026</span> </div>
							<div class="col-sm-10"> <strong>Rach3: A Computational Approach to Study Piano
									Rehearsals</strong><br>
								<a href="https://www.fwf.ac.at/en/research-radar/10.55776/PAT8820923">Austrian Science
									Fund (FWF)</a><br>
								Principal Investigator: Carlos Cancino-Chacón<br>
								Awarded funding <strong>€457,812.00</strong>
							</div>
						</div>


					</div>
				</div>

				<div class="row" id="teaching_experience">
					<div class="col-md-9">
						<br><br>
						<h4 data-appear-animation="fadeInLeft">TEACHING EXPERIENCE<strong> </strong></h4>

						<div class="row">
							<div class="col-sm-2"><span style="font-size:19px;color:#2fd6f7;">2021 - present </span>
							</div>
							<div class="col-sm-10"> <strong>Johannes Kepler University Linz, Austria. </strong><br>
								Assistant Professor at the Institute of Computational Perception<br>
								Courses:<br>
								<a
									href="https://www.jku.at/en/institut-fuer-computational-perception/lehre/alle-lehrveranstaltungen/special-topics-musical-informatics/">Musical
									Informatics</a> (undergraduate and master's level)<br>
								<a
									href="https://www.jku.at/en/institute-of-computational-perception/teaching/all-courses/reinforcement-learning/">Reinforcement
									Learning
								</a>(undergraduate level)<br>
								<a
									href="https://www.jku.at/en/institute-of-computational-perception/teaching/alle-lehrveranstaltungen/seminars/">Seminar
									in Artificial Intelligence</a> (undergraduate/master's level)<br>
								<a
									href="https://www.jku.at/en/institute-of-computational-perception/teaching/alle-lehrveranstaltungen/seminars/">Seminar
									in Data Science</a> (master's level)<br>
								<a
									href="https://www.jku.at/en/institute-of-computational-perception/teaching/alle-lehrveranstaltungen/machine-learning-and-pattern-classification-vl-ue/">Machine
									Learning and Pattern Classification</a> (exercise track; undergraduate/master's
								level)<br>
								<a
									href="https://www.jku.at/en/institute-of-computational-perception/teaching/alle-lehrveranstaltungen/artificial-intelligence-ue/">Artificial
									Intelligence</a> (exercise track; undergraduate level)<br>
								<br><br>
							</div>

							<div class="col-sm-2"><span style="font-size:19px;color:#2fd6f7;">2023</span> </div>
							<div class="col-sm-10"> <strong>University of Music and Performing Arts Vienna, Austria.
								</strong><br>
								External Lecturer at the <a href=https://iwk.mdw.ac.at>Department of Music Acoustics
									Wiener Klangstil</a><br>
								Courses:
								Music Computing (PhD level)
								<br><br>
							</div>



							<div class="col-sm-2"><span style="font-size:19px;color:#2fd6f7;">2011 </span> </div>
							<div class="col-sm-10"> <strong>National Conservatory of Music, Mexico City, Mexico.
								</strong><br>
								Course Lecturer (Level B) <br>
								Courses: Elementary Music Theory I and Harmony Levels I-III (undergraduate level)
								<!-- <br> -->
								<!-- TPTC0101	Solfeo I<br> -->
								<!-- TPTC0306	Armonía Diatónica<br> -->
								<!-- TPTC0409 	Armonía Cromática<br> -->
								<!-- PATC0101	Armonía Contemporánea -->
								<!-- <br><br> -->
							</div>
						</div>
					</div>
				</div>


				<div class="row" id="awards">
					<div class="col-md-9">
						<br> <br>

						<h4 data-appear-animation="fadeInLeft">SCHOLARSHIPS AND AWARDS <strong></strong></h4>

						<div class="row">


							<div class="col-sm-2"><span style="font-size:19px;color:#2fd6f7;">2012 - 2014 </span> </div>
							<div class="col-sm-10"> <strong>Fundación INBA – CONACYT Scholarship of the Mexican National
									Council for Science and Technology (CONACyT)</strong><br><br></div>
						</div>
						<div class="row">


							<div class="col-sm-2"><span style="font-size:19px;color:#2fd6f7;">2017 </span> </div>
							<div class="col-sm-10"> <strong>Award for Creative Achievement at the AccompaniX
									Competition, <br>2017 Turing Tests in the Creative Arts.</strong><br>
								$500 team award for development of an expressive computer accompaniment system.<br><br>
							</div>
						</div>

						<div class="row">


							<div class="col-sm-2"><span style="font-size:19px;color:#2fd6f7;">2021 </span> </div>
							<div class="col-sm-10">
								<strong>Breakthrough of the Year (in the category Art and Science; as part of Gerhard
									Widmer's team),
									<br>Falling Walls Science Summit 2021.</strong><br>
								Lead developer of the ACCompanion, an expressive computer accompaniment system,
								including a live demonstration.<br>
								<a href="https://youtu.be/KE6WhYxuWLk">(video of Gerhard Widmer's talk including live
									demo)</a> <br><br>
							</div>
						</div>

					</div>
				</div>
				<br>
				A pdf version of this CV can be found <a href="documents/other/CancinoChacon_CV.pdf">here</a>.

				<hr class="tall" id="publications" /><br>
				<div class="row">
					<div class="col-md-9">
						<h3 data-appear-animation="fadeInLeft"><strong>PUBLICATIONS </strong></h3>
						<h4 data-appear-animation="fadeInLeft">PEER REVIEWED PUBLICATIONS</h4>

						<div class="row">


							<div class="col-sm-11">
								<ul>
									<li>
										<p>
											S. Chiruthapudi, A. Štefunko, J. Hajič jr. and C. E. Cancino-Chacón
											(2025)<br>
											<strong>&ldquo;Challenges in Basso Continuo Performance-to-Score
												Alignment&rdquo;</strong><br>
											In <em>Proceedings of the 17th International Symposium on Computer Music
												Multidisciplinary Research (CMMR 2025)</em>, London, UK <a
												href="documents/peer_reviewed/ChiruthapudiEtAl-CMMR-2025.pdf">(pdf)</a>
										</p>
									</li>
									<li>
										<p>
											A. Morsi, S. Chiruthapudi, S. Peter, I. Pilkov, L. Bishop, A. Maezawa, X.
											Serra and C. Cancino-Chacón (2025)<br>
											<strong>&ldquo;Enabling Empirical Analysis of Piano Performance Rehearsal
												with the Rach3 MIDI Dataset&rdquo;</strong><br>
											In <em>Proceedings of the 26th International Society for Music Information
												Retrieval Conference (ISMIR 2025)</em>, Daejeon, South Korea <a
												href="documents/peer_reviewed/MorsiEtAl-ISMIR-2025.pdf">(pdf)</a>
										</p>
									</li>
									<li>
										<p>
											J. Park, C. Cancino-Chacón, S. Chiruthapudi and J. Nam (2025)<br>
											<strong>&ldquo;Matchmaker: An Open-Source Library for Real-Time Piano Score
												Following and Systematic Evaluation&rdquo;</strong><br>
											In <em>Proceedings of the 26th International Society for Music Information
												Retrieval Conference (ISMIR 2025)</em> <a
												href="documents/peer_reviewed/ParkEtAl-ISMIR-2025.pdf">(pdf)</a>
										</p>
									</li>
									<li>
										<p>
											A. Štefunko, S. Chiruthapudi, J. Hajič jr. and C. E. Cancino-Chacón
											(2025)<br>
											<strong>&ldquo;Basso Continuo Goes Digital: Collecting and Aligning a
												Symbolic Dataset of Continuo Performance&rdquo;</strong><br>
											In <em>Proceedings of the 6th Conference on AI Music Creativity (AIMC
												2025)</em>, Brussels, Belgium <a
												href="documents/peer_reviewed/ŠtefunkoEtAl-AIMC-2025.pdf">(pdf)</a>
										</p>
									</li>
									<li>
										<p>
											O. Lartillot, D. Swarbrick, F. Upham and C. E. Cancino-Chacón (2025)<br>
											<strong>&ldquo;Video Visualization of a String Quartet Performance of a Bach
												Fugue: Design and Subjective Evaluation&rdquo;</strong><br>
											<em>Music & Science</em> <a
												href="documents/peer_reviewed/LartillotEtAl-MS-2025.pdf">(pdf)</a>
										</p>
									</li>
									<li>
										<p>
											S. Høffding, R. J. F. Bergstrøm, L. Bishop, P. Lucas, K. Burnim, C.
											Cancino-Chacón, A. Clim, M. Good, N. C. Hansen, E. S. Karlsen, L. H. Kvale,
											B. Laeng, O. Lartillot, E. Lippert, R. Martin, N. Nielsen, R. Omprakash, T.
											S. Paulsrud, F. Rosas, D. Swarbrick, S. Sørbø, F. Upham, A. Vrasdonk, J.
											Vuoskoski, S. Wallot, W. Yi, A. Danielsen and A. R. Jensenius (2025)<br>
											<strong>&ldquo;Introducing the MusicLab Copenhagen
												Dataset&rdquo;</strong><br>
											<em>Music & Science</em> <a
												href="documents/peer_reviewed/HøffdingEtAl-MS-2025.pdf">(pdf)</a>
										</p>
									</li>
									<li>
										<p>
											U. Zivanovic, I. Pilkov and C. E. Cancino-Chacón (2025)<br>
											<strong>&ldquo;Pay Attention to the Keys: Visual Piano Transcription Using
												Transformers&rdquo;</strong><br>
											In <em>Proceedings of the 34th International Joint Conference on Artificial
												Intelligence</em>, Montreal, Canada <a
												href="documents/peer_reviewed/ZivanovicEtAl-IJCAI-2025.pdf">(pdf)</a>
										</p>
									</li>
									<li>
										<p>
											H. Zhang, S. Chowdhury, C. E. Cancino-Chacón, J. Liang, S. Dixon and G.
											Widmer (2024)<br>
											<strong>&ldquo;DExter: Learning and Controlling Performance Expression with
												Diffusion Models&rdquo;</strong><br>
											<em>Applied Sciences</em> <a
												href="documents/peer_reviewed/ZhangEtAl-AS-2024.pdf">(pdf)</a>
										</p>
									</li>
									<li>
										<p>
											P. Hu, L. S. Marták, C. Cancino-Chacón and G. Widmer (2024)<br>
											<strong>&ldquo;Towards Musically Informed Evaluation of Piano Transcription
												Models&rdquo;</strong><br>
											In <em>Proceedings of the 25th International Society for Music Information
												Retrieval Conference (ISMIR 2024)</em>, San Francisco, USA <a
												href="documents/peer_reviewed/HuEtAl-ISMIR-2024.pdf">(pdf)</a>
										</p>
									</li>
									<li>
										<p> C. Cancino-Chacón and I. Pilkov (2024)<br>
											<strong>&ldquo;The Rach3 Dataset: Towards Data-Driven Analysis of Piano
												Performance Rehearsal&rdquo;</strong><br>
											In <em>Proceedings of the 30th International Conference on Multimedia
												Modelling MMM24</em>, Amsterdam, The Netherlands.
											<!-- <a
												href="documents/peer_reviewed/CancinoEtAl-MMM-2024.pdf">(pdf)</a> -->
											<a
												href="https://link.springer.com/chapter/10.1007/978-3-031-56435-2_3">(link)</a>
										</p>
									</li>
									<li>
										<p>
											S. D. Peter, S. Chowdhury, C. Cancino-Chacón and G. Widmer (2023)<br>
											<strong>&ldquo;Are we describing the same sound? An analysis of word
												embedding spaces of expressive piano performance&rdquo;</strong><br>
											In <em>FIRE'23: Proceedings of the 15th Annual Meeting of the Forum for
												Information Retrieval Evaluation</em>, Panjim, India <a
												href="documents/peer_reviewed/PeterEtAl-FIRE-2023.pdf">(pdf)</a>
										</p>
									</li>
									<li>
										<p>
											S. D. Peter, C. Cancino-Chacón, E. Karystinaios and G. Widmer (2023)<br>
											<strong>&ldquo;Sounding out reconstruction error-based evaluation of
												generative models of expressive performance&rdquo;</strong><br>
											In <em>Proceedings of the 10th International Conference on Digital Libraries
												for Musicology DLfM'23</em>, Milan, Italy <a
												href="documents/peer_reviewed/PeterEtAl-DLfM-2023.pdf">(pdf)</a>
										</p>
									</li>
									<li>
										<p> H. Zhang, E. Karystinaios, S. Dixon, G. Widmer and C. Cancino-Chacón
											(2023)<br>
											<strong>&ldquo;Symbolic Music Representations for Classification Tasks: A
												Systematic Evaluation&rdquo;</strong><br>
											In <em>Proceedings of the 24th International Society for Music Information
												Retrieval Conference (ISMIR 2023),</em> Milan, Italy.
											<a href="documents/peer_reviewed/ZhangEtAl-ISMIR-2023.pdf">(pdf)</a>
										</p>
									</li>
									<li>
										<p> S. Peter, C. Cancino-Chacón, F. Foscarin, A. P. McLeod, F. Henkel, E.
											Karystinaios and G. Widmer (2023)<br>
											<strong>&ldquo;Automatic Note-Level Score-to-Performance Alignments in the
												ASAP Dataset.&rdquo;</strong> <br>
											Transactions of the International Society for Music Information Retrieval
											Vol. 6(1), pp. 27-42 <a
												href="documents/peer_reviewed/PeterEtAl-TISMIR-2023.pdf">(pdf)</a> <a
												href="https://transactions.ismir.net/articles/10.5334/tismir.149">(link)</a>
											<a href="https://github.com/CPJKU/asap-dataset">(dataset)</a>
										</p>
									</li>
									<li>
										<p> C. Cancino-Chacón, S. Peter, P. Hu, E. Karystinaios, F. Henkel, F. Foscarin,
											N. Varga
											and G. Widmer (2023)<br>
											<strong>&ldquo;The ACCompanion: Combining Reactivity, Robustness, and
												Musical Expressivity in an Automatic Piano Accompanist&rdquo;</strong>
											<br>
											In <em>Proceedings of the 32nd International Joint Conference on Artificial
												Intelligence (IJCAI-23),</em> Macao, S. A. R. <a
												href="documents/peer_reviewed/CancinoEtAl-IJCAI-2023.pdf">(pdf)</a> <a
												href="https://cpjku.github.io/accompanion_ijcai2023/">(supplementary
												material)</a> <a
												href="https://github.com/CPJKU/accompanion">(github)</a> <a
												href="https://youtube.com/playlist?list=PLPUWmNCGflVNxPppflMNFMzWedlOhZePO&si=jh-qaoll2__4lgGk">(playlist)</a>

										</p>
									</li>
									<li>
										<p> C. Cancino-Chacón (2023)<br>
											<strong>&ldquo;Commentary on A Computational Approach to Detection and
												Prediction of (Ir)Regularity in Children's Folk Songs.&rdquo;</strong>
											<br>
											Empirical Musicology Review Vol. 16(2) <a
												href="documents/peer_reviewed/Cancino-EMR-2023.pdf">(pdf)</a> <a
												href="https://emusicology.org/index.php/EMR/article/view/9159/7811">(link)</a>

										</p>
									</li>
									<li>
										<p> C. Cancino-Chacón, S. Peter, E. Karystinaios, F. Foscarin, M. Grachten and
											G. Widmer (2022)<br>
											<strong>&rdquo;Partitura: A Python Package for Symbolic Music
												Processing&rdquo;</strong><br>
											In <em>Proceedings of the Music Encoding Conference (MEC2022)</em>, Halifax,
											Canada <a href="documents/peer_reviewed/CancinoEtAl-MEC-2022.pdf">(pdf)</a>
											<a href="https://github.com/CPJKU/partitura/">(github)</a>
										</p>
									</li>
									<li>
										<p> F. Foscarin, E. Karystinaios, S. Peter, C. Cancino-Chacón, M. Grachten and
											G. Widmer (2022)<br>
											<strong>&rdquo;The match file format: Encoding Alignments between Scores and
												Performances&rdquo;</strong><br>
											In <em>Proceedings of the Music Encoding Conference (MEC2022)</em>, Halifax,
											Canada <a href="documents/peer_reviewed/FoscarinEtAl-MEC-2022.pdf">(pdf)</a>
										</p>
									</li>
									<li>
										<p> L. Bishop, C. Cancino-Chacón, W. Goebl (2021)<br>
											<strong>&ldquo;Beyond synchronization: How and why do ensemble performers
												communicate&rdquo;</strong>
											In <em>Together in Music: Participation, Co-Ordination and Creativity in
												Ensembles.</em> R. Timmers, F. Bailes and H. Daffern (eds).<br>
											Oxford University Press. <a
												href="documents/peer_reviewed/BishopEtAl-OUP-2020.pdf">(authors'
												accepted copy)</a>
										</p>
									</li>
									<li>
										<p> C. Cancino-Chacón, S. Peter, S. Chowdhury, A. Aljanaki, G. Widmer (2020)<br>
											<strong>&ldquo;On the Characterization of Expressive Performance in
												Classical Music: First Results of the <em>Con Espressione</em>
												Game&rdquo;</strong><br>
											In <em> Proceedings of the 21th International Society for Music Information
												Retrieval Conference (ISMIR 2020)</em> Montreal, Canada.
											<a href="documents/peer_reviewed/CancinoEtAl-ISMIR-2020.pdf">(pdf)</a>
											<!-- <a href="https://cpjku.github.io/con_espressione_game_ismir2020/">(online extras)</a> -->
											<a href="https://zenodo.org/record/3968828#.Yh3hBi1Q3Jw">(dataset)</a>
											<!-- <a href="http://con-espressione.cp.jku.at">(game)</a> <br> -->
										</p>
									</li>
									<li>
										<p> O. Lartillot, C. Cancino-Chacón, C. Brazier (2020)<br>
											<strong>&ldquo;Real-Time Visualization of Fugue Played by a String
												Quartet&rdquo;</strong><br>
											In <em> Proceedings of the 17th Sound and Music Computing Conference
												(SMC2020)</em> Torino, Italy. <a
												href="documents/peer_reviewed/LartillotEtAl-SMC-2020.pdf">(pdf)</a>
										</p>
									</li>
									<li>
										<p> F. Simonetta, C. Cancino-Chacón, S. Ntalampiras, G. Widmer (2019)<br>
											<strong>&ldquo;A Convolutional Approach to Melody Line Identification in
												Symbolic Scores&rdquo;</strong><br>
											In <em>Proceedings of the 20th International Society for Music Information
												Retrieval Conference (ISMIR 2019)</em> Delft, The Netherlands. <a
												href="documents/peer_reviewed/SimonettaEtAl-ISMIR-2019.pdf">(pdf)</a> <a
												href="https://limunimi.github.io/Symbolic-Melody-Identification/">(supplementary
												materials)</a>
										</p>
									</li>
									<li>
										<p> L. Bishop, C. Cancino-Chacón, W. Goebl (2019)<br>
											<strong>&ldquo;Moving to Coordinate, Moving to Interact: Patterns of Body
												Motion in Musical Duo Performance&rdquo;.</strong><br>
											Music Perception.
											<a href="https://www.doi.org/10.1525/mp.2019.37.1.1">(link)</a>
											<a href="documents/peer_reviewed/BishopEtAl-MP-2019.pdf">(pdf)</a> <br>
									</li>
									<li>
										<p> L. Bishop, C. Cancino-Chacón, W. Goebl (2019)<br>
											<strong>&ldquo;Eye gaze as a means of giving and seeking information during
												musical interaction&rdquo;.</strong><br>
											Consciousness and Cognition. <a
												href="https://doi.org/10.1016/j.concog.2019.01.002">(link)</a> <a
												href="documents/peer_reviewed/BishopEtAl-CC-2019.pdf">(pdf)</a><br>
									</li>
									<li>
										<p> C. E. Cancino-Chacón, M. Gracthen, W. Goebl, G. Widmer (2018)<br>
											<strong>&ldquo;Computational Models of Expressive Music Performance: A
												Comprehensive and Critical Review&rdquo;.</strong><br>
											Frontiers in Digital Humanities. <a
												href="https://doi.org/10.3389/fdigh.2018.00025">(link)</a> <a
												href="documents/peer_reviewed/CancinoEtAl-FIDH-2018.pdf">(pdf)</a><br>
									</li>
									<li>
										<p> G. Velarde, C. Cancino Chacón, D. Meredith, T. Weyde, M. Grachten (2018)<br>
											<strong>&ldquo;Convolution-based classification of audio and symbolic
												representations of music&rdquo;.</strong><br>
											Journal of New Music Research. <a
												href="https://doi.org/10.1080/09298215.2018.1458885">(link)</a><br>
									</li>
									<li>
										<p>C. E. Cancino-Chacón, M. Grachten, D. R. W. Sears, G. Widmer (2017).<br>
											<strong>&ldquo;What were you expecting? Using Expectancy Features to Predict
												Expressive Performances of Classical Piano Music&rdquo;.</strong><br>
											In <em>Proceedings of the 10th International Workshop on Machine Learning
												and Music (MML 2017)</em>. Barcelona, Spain. <a
												href="documents/peer_reviewed/CancinoEtAl-MML-2017.pdf">(pdf)</a><br>
									</li>

									<li>
										<p>C. E. Cancino-Chacón, M. Grachten, K. Agres (2017).<br>
											<strong>&ldquo;From Bach to The Beatles: The Simulation of Human Tonal
												Expectation Using Ecologically-Trained Predictive
												Models&rdquo;.</strong><br>
											In <em>Proceedings of the 18th International Society for Music Information
												Retrieval Conference (ISMIR 2017)</em>. Suzhou, China. <a
												href="documents/peer_reviewed/CancinoEtAl-ISMIR-2017.pdf">(pdf)</a> <a
												href="documents/online_extras/ismir2017/sup_materials.html">(supplementary
												materials)</a><br>
									</li>
									<li>
										<p> C. E. Cancino-Chacón, T. Gadermaier, G. Widmer, M. Grachten (2017) <br>
											<strong>&ldquo;An Evaluation of Linear and Non-Linear Models of Expressive
												Dynamics in Classical Piano and Symphonic Music&rdquo;.</strong><br>
											Machine Learning. Vol. 106(6). Springer. pp. 887-909. <a
												href="documents/peer_reviewed/CancinoEtAl-MLJ-2017.pdf">(pdf)</a>
									</li>
									<li>
										<p> M. Grachten, C. E. Cancino-Chacón, T. Gadermaier, G. Widmer (2017) <br>
											<strong>&ldquo;Towards computer-assisted understanding of dynamics in
												symphonic music&rdquo;.</strong><br>
											IEEE Multimedia. Vol. 24(1), pp. 36-46. <a
												href="documents/peer_reviewed/GrachtenEtAl-IEEEMM-2017.pdf">(authors'
												accepted copy)</a><br>
										</p>
									</li>
									<li>
										<p> M. Grachten, C. E. Cancino Chacón (2017). <br>
											<strong>&ldquo;Temporal dependencies in the expressive timing of classical
												piano performances&rdquo;.</strong><br>
											In <em>the Routledge Companion of Embodied Music Interaction</em>. M.
											Lessafre, M. Leman and P. J. Maes (Eds). Routledge. pp. 362-371. <a
												href="documents/peer_reviewed/GrachtenEtAl-RoutledgeEMI-2017.pdf">(authors'
												accepted copy)</a>
										</p>
									</li>
									<li>
										<p>G. Velarde, T. Weyde, C. E. Cancino Chacón, D. Meredith, M. Grachten (2016).
											<br>
											<strong>&ldquo;Composer Recognition based on 2D-Filtered Piano-Rolls&rdquo;.
											</strong><strong> </strong><br>
											In <em>Proceedings of the 17th International Society for Music Information
												Retrieval Conference (ISMIR 2016)</em>, New York City, NY, USA. <a
												href="documents/peer_reviewed/VelardeEtAl-ISMIR-2016.pdf">(pdf)</a>
										</p>
									</li>
									<li>
										<p>T. Gadermaier, M. Grachten, C. E. Cancino Chacón (2016). <br>
											<strong>&ldquo;Modeling Loudness Variations in Ensemble Performance&rdquo;.
											</strong><strong> </strong><br>
											In <em>Proceedings of the 2nd International Conference on New Music Concepts
												(ICNMC 2016)</em>. Treviso, Italy. <a
												href="documents/peer_reviewed/GadermaierEtAl-icnmc-2016.pdf">(pdf)</a>
										</p>
									</li>
									<li>
										<p>C. E. Cancino Chacón and M. Grachten (2015). <br>
											<strong>&ldquo;</strong><strong>An evaluation of score descriptors combined
												with non-linear models of expressive dynamics in
												music</strong><strong>&rdquo;. </strong><br>
											In <em>Proceedings of the 18th</em> <em>International Conference on
												Discovery Science (DS2015)</em>. Banff, Canada. <a
												href="documents/peer_reviewed/CancinoEtAl-DS-2015.pdf">(pdf)</a>
										</p>
									</li>
									<li>
										<p>S. Lattner, C. E. Cancino Chacón and M. Grachten (2015). <br>
											<strong>&ldquo;</strong><strong>Pseudo-Supervised Training Improves
												Unsupervised Melody Segmentation</strong><strong>&rdquo;. </strong><br>
											In <em>Proceedings of the International Joint Conference on Artificial
												Intelligence (IJCAI). </em>Buenos Aires, Argentina. <a
												href="documents/peer_reviewed/LattnerEtAl-IJCAI-2015.pdf">(pdf)</a>
										</p>
									</li>
									<li>
										<p>S. Lattner, M. Grachten, K. Agres and C. E. Cancino Chacón (2015). <br>
											<strong>&ldquo;</strong><strong>Probabilistic Segmentation of Musical
												Sequences using Restricted Boltzmann Machines</strong><strong>&rdquo;.
											</strong><br>
											In <em>Proceedings of the Fifth Biennial International Conference on
												Mathematics and Computation in Music (MCM2015)</em>. London, UK. <a
												href="documents/peer_reviewed/LattnerEtAl-MCM-2015.pdf">(pdf)</a>
										</p>
									</li>
									<li>
										<p>K. Agres, C. E. Cancino Chacón, M. Grachten and S. Lattner (2015). <br>
											<strong>&ldquo;</strong><strong>Harmonics co-occurrences bootstrap pitch and
												tonality perception in music: Evidence from a statistical unsupervised
												learning model</strong><strong>&rdquo;. </strong><br>
											<em>The Annual Meeting of the Cognitive Science Society (CogSci2015)</em>.
											Pasadena, CA, USA. <a
												href="documents/peer_reviewed/AgresEtAl-CogSci-2015.pdf">(pdf)</a><br>
										</p>
									</li>
									<li>
										<p> C. E. Cancino Chacón, S. Lattner, M. Grachten
											(2014).<br><strong>&ldquo;Developing tonal perception through unsupervised
												learning&rdquo;. </strong><br>
											In <em>Proceedings of the15th International Society for Music Information
												Retrieval Conference (ISMIR 2014)</em>. Taipei, Taiwan. <a
												href="documents/peer_reviewed/CancinoEtAl-ISMIR-2014.pdf">(pdf)</a></p>
									</li>
									<li>
										<p>C. E. Cancino Chacón and P. Mowlaee (2014). <br>
											<strong>&ldquo;Least Squares phase estimation of mixed signals&rdquo;.
											</strong><br>
											In <em>Proceedings of the</em> <em>15th Annual Conference of the
												International Speech Communication Association (INTERSPEECH 2014).
											</em>Singapore. <a
												href="documents/peer_reviewed/CancinoEtAl-INTERSPEECH-2014.pdf">(pdf)</a>
										</p>
									</li>
									<li>
										<p>M. Grachten, C. E. Cancino Chacón and G. Widmer (2014). <br>
											<strong>&ldquo;</strong><strong>Analysis and prediction of expressive
												dynamics using Bayesian linear models</strong><strong>&rdquo;.
											</strong><br>
											In Proceedings of the <em>1st International W</em><em>orkshop on computer
												and roboti</em><em>c </em><em>Systems for Automatic Music
												Performance</em><em> (SAMP14).</em> Venice, Italy. <a
												href="documents/peer_reviewed/GrachtenEtAl-SAMP-2014.pdf">(pdf)</a>
										</p>
									</li>
									<li>
										<p>S. Tschiatschek, C. E. Cancino Chacón, and F. Pernkopf (2013). <br>
											<strong>&ldquo;</strong><strong>Bounds for Bayesian Network Classifiers with
												Reduced Precision Parameters</strong><strong>&rdquo;, </strong><br>
											In <em>Proceedings of the 2013</em> <em>IEEE International Conference on
												Acoustics, Speech, and Signal Processing (ICASSP</em><em> 2013)</em>.
											Vancouver, Canada. <a
												href="documents/peer_reviewed/TschiatschekEtAl-ICASSP-2013.pdf">(pdf)</a>
										</p>
									</li>
								</ul>
							</div>
						</div>

						<h4 data-appear-animation="fadeInLeft">EXTENDED ABSTRACTS</h4>
						<div class="row">
							<div class="col-sm-11">
								<ul>
									<li>
										<p>
											C. Cancino-Chacon, I. Pilkov and L. Bishop (2025)<br>
											<strong>&ldquo;Hanon Hands: Examining Timing Variability in Pianists&#x27;
												Hand and Finger Motion at Fast and Slow Tempi&rdquo;</strong><br>
											In <em>Extended Abstracts of the International Symposium on Performance
												Science (ISPS 2025)</em>, Shanghai, China <a
												href="documents/extended_abstracts/CancinoChaconEtAl-ISPS-2025.pdf">(pdf)</a>
										</p>
									</li>
									<li>
										<p>
											P. Hu, S. D. Peter, C. Cancino-Chacón and G. Widmer (2025)<br>
											<strong>&ldquo;Exploring Musical Time at the Phrase, Metre and Motif
												Level&rdquo;</strong><br>
											In <em>Abstracts of the 20th Rhythm Perception & Production Workshop
												(RPPW20)</em>, Jyväskylä, Finland <a
												href="documents/extended_abstracts/HuEtAl-RPPW-2025.pdf">(pdf)</a>
										</p>
									</li>
									<li>
										<p>
											J. Park, C. Cancino-Chacón, T. Kwon and J. Nam (2024)<br>
											<strong>&ldquo;Matchmaker: A Python Library for Real-Time Music
												Alignment&rdquo;</strong><br>
											In <em>Extended Abstracts for the Late-Breaking Demo Session of the 25th
												Int. Society for Music Information Retrieval Conference</em>, San
											Francisco, USA <a
												href="documents/extended_abstracts/ParkEtAl-ISMIR-LBD-2024.pdf">(pdf)</a>
										</p>
									</li>
									<li>
										<p>C. Cancino-Chacón, S. Peter, G. Widmer (2022)<br>
											<strong>&ldquo;Can We Achieve Togetherness with an Artificial Partner?
												Insights and Challenges from Developing an Automatic Accompaniment
												System&rdquo;</strong><br>
											Musical Togetherness Symposium (MTS), Vienna, Austria <a
												href="documents/extended_abstracts/CancinoEtAl-MTS-2022_abstract.pdf">(pdf)</a>

										</p>
									</li>
									<li>
										<p>C. Cancino-Chacón, S. Peter, E. Karystinaios, G. Widmer (2021)<br>
											<strong>&ldquo;Towards Quantifying Differences in Expressive Piano
												Performances: Are Euclidean-like Distance Measures
												Enough?&rdquo;</strong><br>
											Rhythm Production and Perception Workshop 2021 (RPPW2021), Oslo, Norway.
											<a
												href="documents/extended_abstracts/CancinoChaconEtAl-RPPW2021.pdf">(pdf)</a>
										</p>
									</li>
									<li>
										<p>C. Cancino-Chacón, S. Peter, S. Chowdhury, A. Aljanaki, G. Widmer (2021)<br>
											<strong>&ldquo;Sorting Musical Expression: Characterization of Descriptions
												of Expressive Piano Performances&rdquo;</strong><br>
											16th International Conference on Music Perception and Cognition
											(ICMPC16-ESCOM11), Sheffield, UK.
											<a
												href="documents/extended_abstracts/CancinoChaconEtAl-ICMPC2021.pdf">(pdf)</a>
											<a href="https://youtu.be/EaantgFqUYE">(video)</a>
											<a href="https://sildater.github.io/expressivity/">(interactive demo)</a>
										</p>
									<li>
										<p>M. Grachten, C. Cancino-Chacón, T. Gadermaier (2019) <br>
											<strong>&ldquo;partitura: A Python Package for Handling Symbolic Musical
												Data&rdquo;</strong><br>
											Late Breaking/Demo at the 20th International Society for Music Information
											Retrieval Conference (ISMIR 2019), Delft, The Netherlands.
											<a
												href="documents/extended_abstracts/GrachtenEtAl-ISMIR2019-LBD-ext-abstract.pdf">(pdf)</a>
											<a href="https://github.com/mgrachten/partitura">(code)</a>
											<a
												href="https://partitura.readthedocs.io/en/latest/index.html">(documentation)</a>
										</p>
									</li>

									<li>
										<p>D. Weigl, C. Cancino-Chacón, M. Bonev, W. Goebl (2019), <br>
											<strong>&ldquo;Linking and Visualising Performance Data and Semantic Music
												Encodings in Real-time&rdquo;</strong><br>
											Late Breaking/Demo at the 20th International Society for Music Information
											Retrieval Conference (ISMIR 2019), Delft, The Netherlands.
											<a
												href="documents/extended_abstracts/WeiglEtAl-ISMIR2019-LBD-ext-abstract.pdf">(pdf)</a>
										</p>
									</li>
									<li>
										<p>C. Cancino-Chacón, S. Balke, F. Krebs, C. Stussak, G. Widmer (2019), <br>
											<strong>&ldquo;The <i>Con Espressione!</i> Exhibit: Exploring Human-Machine
												Collaboration in Expressive Performance&rdquo;</strong><br>
											Late Breaking/Demo at the 20th International Society for Music Information
											Retrieval Conference (ISMIR 2019), Delft, The Netherlands.
											<a
												href="documents/extended_abstracts/CancinoEtAl-ISMIR2019-LBD-ext-abstract.pdf">(pdf)</a>
											<a href="https://www.youtube.com/watch?v=GRGIz4pE-wc">(video)</a>
											<a href="https://github.com/IMAGINARY/con-espressione">(code)</a>
										</p>
									</li>
									<li>
										<p>Z. Shi, C. Cancino-Chacón, G. Widmer (2019), <br>
											<strong>&ldquo;User Curated Shaping of Expressive
												Performances&rdquo;</strong><br>
											Invited Talk at the ICML 2019 Workshop on Machine Learning for Music
											Discovery, 36th International Conference on Machine Learning (ICML 2019),
											Long Beach, CA, USA.
											<a href="documents/extended_abstracts/ShiEtAl-ML4MD-2019.pdf">(pdf)</a>
										</p>
									</li>

									<li>
										<p>C. E. Cancino-Chacón, M. Grachten (2018), <br>
											<strong>&ldquo;A Computational Study of the Role of Tonal Tension in
												Expressive Piano Performance&rdquo;</strong><br>
											Proceedings of the 15th International Conference on Music Perception and
											Cognition (ICMPC15 ESCOM10), Graz, Austria.
											<a href="documents/extended_abstracts/CancinoEtAl-ICMPC15-proceedings.pdf">(proceedings
												pdf)</a>
											<a href="documents/extended_abstracts/CancinoEtAl-ICMPC15-abstract.pdf">(abstract
												pdf)</a>
											<a
												href="documents/extended_abstracts/CancinoEtAl-ICMPC15-poster.pdf">(poster)</a>
										</p>
									</li>

									<li>
										<p>L. Bishop, C. E. Cancino-Chacón, W. Goebl (2018), <br>
											<strong>&ldquo;Visual Signals between Improvisers Indicate Attention rather
												than Intentions&rdquo;</strong><br>
											Proceedings of the 15th International Conference on Music Perception and
											Cognition (ICMPC15 ESCOM10), Graz, Austria.
											<a
												href="documents/extended_abstracts/BishopEtAl-ICMPC15-abstract.pdf">(pdf)</a>
										</p>
									</li>

									<li>
										<p>C. E. Cancino-Chacón, M. Bonev, A. Durand, M. Grachten, A. Arzt, L. Bishop,
											W. Goebl, G. Widmer (2017), <br>
											<strong>&ldquo;The ACCompanion v0.1: An Expressive Accompaniment
												System&rdquo;. </strong><strong> </strong><br>
											Late Breaking/Demo at the 18th International Society for Music Information
											Retrieval Conference (ISMIR 2017), Suzhou, China.
											<a
												href="documents/extended_abstracts/CancinoEtAl-ISMIR2017-LBD-ext-abstract.pdf">(pdf)</a>
											<a
												href="documents/extended_abstracts/CancinoEtAl-ISMIR2017-LBD-poster.pdf">(poster)</a>
											<a href="documents/online_extras/ismir2017lbd/online_extras.html">(supplementary
												materials)</a>
										</p>
									</li>
									<li>
										<p>L. Bishop, C. E. Cancino-Chacón, W. Goebl (2017), <br>
											<strong>&ldquo;Mapping Visual Attention of Duo Musicians During Rehearsal of
												Temporally-Ambiguous Music&rdquo;. </strong><strong> </strong><br>
											In Proceedings of the International Symposium on Performance Science (ISPS
											2017), Reykjavik, Iceland. <a
												href="documents/extended_abstracts/BishopEtAl-ISPS2017_abstract.pdf">(pdf)</a>
										</p>
									</li>

									<li>
										<p>C. E. Cancino Chacón, M. Grachten (2016), <br>
											<strong>&ldquo;The Basis Mixer: A Computational Romantic Pianist&rdquo;..
											</strong><strong> </strong><br>
											Late Breaking/Demo at the 17th International Society for Music Information
											Retrieval Conference (ISMIR 2016), New York, USA.
											<a
												href="documents/extended_abstracts/CancinoGrachten-ISMIR2016-LBD-ext-abstract.pdf">(pdf)</a>
											<a
												href="documents/extended_abstracts/CancinoGrachten-ISMIR2016-LBD-poster.pdf">(poster)</a>
											<a href="https://basismixer.cp.jku.at/static/app.html">(web app)</a>
											<a href="documents/online_extras/basis_mixer/basis_mixer.html">(supplementary
												materials)</a>
										</p>
									</li>


								</ul>
							</div>
						</div>

						<h4 data-appear-animation="fadeInLeft">INVITED TALKS AND TUTORIALS</h4>
						<div class="row">
							<div class="col-sm-11">
								<ul>
									<li>
										<p>C. Cancino-Chacón (December 2024)<br>
											<strong>&ldquo;An AI Dress Rehearsal: Exploring Music Performance and Interaction with Computational Models&rdquo;</strong><br>
											Keynote Talk Presented at the 1st Latin American Music Information Retrieval Workshop, Rio de Janeiro, Brazil <a
												href="https://www.youtube.com/watch?v=8M819AFaG8U&list=PLD-eOOIdZMYQy-KBT8fpOP2otXCrPHtkS&index=5">(video)</a>
										</p>
									</li>
									<li>
										<p>C. Cancino-Chacón (December 2023)<br>
											<strong>&ldquo;Towards Expressive Artificial Musical
												(Co-)performers&rdquo;</strong><br>
											Invited talk at the 6th LatAm BISH Bash, online <a
												href="https://youtu.be/fS2ttgEiBC0?si=_ApPgi26vq-aJWkd">(video)</a>
										</p>
									</li>
									<li>
										<p>C. Cancino-Chacón (December 2023)<br>
											<strong>&ldquo;Towards Expressive Artificial Musical
												(Co-)performers&rdquo;</strong><br>
											Invited talk at the International Symposium on AI and Music Performance,
											Daejeon, South Korea <a
												href="https://youtu.be/9JuOMvHEN1I?si=XOfl2_xHH3Os-gWO">(video)</a>

										</p>
									</li>
									<li>
										<p>C. Cancino-Chacón (June 2023)<br>
											<strong>&ldquo;Towards Understanding Emotion Communicated Through
												Performance of Orchestral Music: Preliminary
												Results"&rdquo;</strong><br>
											Invited Talk at the 2nd MIRAGE Symposium, RITMO
											Centre for Interdisciplinary Studies in Rhythm, Time and Motion, University
											of Oslo, Norway.
										</p>
									</li>
									<li>
										<p> C. Cancino-Chacón, F. Foscarin, E. Karystinaios, S. Peter (December
											2022)<br>
											<strong>&ldquo;An Introduction to Symbolic Music Processing with
												Partitura&rdquo;</strong><br>
											Tutorial presented at the 23rd International Society for Music Information
											Retrieval Conference (ISMIR 2022), Bengaluru, India <a
												href="https://ismir2022.ismir.net/program/tutorials">(abstract)</a> <a
												href="https://cpjku.github.io/partitura_tutorial/">(notebooks)</a>
										</p>
									</li>
									<li>
										<p> C. Cancino-Chacón (September 2022)<br>
											<strong>&ldquo;Play it Again, Hall 9000! Towards Expressive Computational
												Performers&rdquo;</strong><br>
											Invited talk at the Max Plank Instutitute for Intelligent Systems, Tübingen,
											Germany.
										</p>
									</li>
									<li>
										<p>O. Lartillot, E. Guldbransen, C. E. Cancino-Chacón (June 2021), <br>
											<strong>&ldquo;Dynamics analysis, and application to a comparative study of
												Bruckner performances&rdquo;</strong><br>
											Invited Talk at the MIRAGE Symposium #1: Computational Musicology, RITMO
											Centre for Interdisciplinary Studies in Rhythm, Time and Motion, University
											of Oslo, Norway.
											<a
												href="https://mediasite.nb.no/Mediasite/Play/e19e44a100be48668886995063f48e2d1d?autostart=true&player=50a54cab1d3541bc913f556ea1b6df590a&playfrom=13872000&covertitle=false">(video)</a>
										</p>
									</li>
									<li>
										<p> C. E. Cancino-Chacón (April 2020),<br>
											<strong>&ldquo;I'll be Bach! Modeling Expressive Performance with Machine
												Learning&rdquo;</strong><br>
											Invited Talk at the Food & Paper Talk Series, RITMO Centre for
											Interdisciplinary Studies in Rhythm, Time and Motion, University of Oslo,
											Norway.
											<a
												href="https://www.uio.no/ritmo/english/news-and-events/events/food-and-paper/2020/cancino-chacon/index.html">(abstract)</a>
										</p>
									</li>
									<li>
										<p> C. E. Cancino-Chacón (March 2020), <br>
											<strong>&ldquo;Machine Listening of Orchestral
												Recordings&rdquo;</strong><br>
											Invited Talk at the Workshop on Musical Listening, University of Oslo,
											Norway.
									</li>
									<li>
										<p> C. E. Cancino-Chacón, K. Kosta, M. Grachten (November 2019), <br>
											<strong>&ldquo;Computational Modeling of Musical Expression: Perspectives,
												Datasets, Analysis and Generation&rdquo;</strong><br>
											Tutorial presented at the 20th International Society for Music Information
											Retrieval Conference (ISMIR 2019), Delft, The Netherlands.
											<a href="https://ismir2019.ewi.tudelft.nl/?q=node/39">(abstract)</a>
											<a href="documents/invited_talks/ismir2019_T4_slides.pdf">(slides)</a>
											<a href="https://ofai.github.io/ismir2019_expressive_performance_tutorial/">(supplementary
												materials)</a>
										</p>
									</li>
									<li>
										<p>C. E. Cancino-Chacón (March 2019), <br>
											<strong>&ldquo;Modeling Expressive Music Performance with Non-linear Basis
												Function Models&rdquo;</strong><br>
											Invited Talk at the Deep Learning Seminar, University of Vienna, Austria. <a
												href="https://www.univie.ac.at/projektservice-mathematik/e/index.php?event=DL-SEM&page=talk-details&id=462">(abstract)</a>
										</p>
									</li>
									<li>
										<p>C. E. Cancino-Chacón (January 2019), <br>
											<strong>&ldquo;Computational Modeling of Expressive Music Performance with
												Linear and Non-linear Basis Function Models&rdquo;</strong><br>
											Invited Talk at the Austrian Research Institute for Artificial Intelligence,
											Vienna, Austria. <br>
									</li>
									<li>
										<p>C. E. Cancino-Chacón (November 2016), <br>
											<strong>&ldquo;¿Escuchan los androides música electrónica?&rdquo;
											</strong><strong> </strong><br>
											Invited Talk at the Talk series: Pláticas DeMentes. Faculty of Psychology,
											National Autonomous University of Mexico. <a
												href="documents/invited_talks/CancinoChacon_UNAM_Nov2016.pdf">(abstract
												pdf)</a>
										</p>
									</li>
									<li>
										<p>C. E. Cancino-Chacón (November 2016), <br>
											<strong>&ldquo;En busca del factor Mozart&rdquo; </strong><br>
											Invited Talk at the National Conservatory of Music. Mexico City, Mexico. <a
												href="documents/invited_talks/CancinoChacon_CNM_Nov2016.pdf">(abstract
												pdf)</a>
										</p>
									</li>
								</ul>
							</div>
						</div>

						<h4 data-appear-animation="fadeInLeft">THESES</h4>
						<div class="row">
							<div class="col-sm-11">
								<ul>
									<li>
										<p>C. E. Cancino Chacón (2018), <br>
											<strong>&ldquo;Computational Modeling of Expressive Music Performance with
												Linear and Non-linear Basis Function Models&rdquo;.</strong><br>
											Johannes Kepler University Linz, Austria.
											<a href="documents/thesis/Cancino-JKU-2018.pdf">(pdf)</a>
											<a href="documents/online_extras/phd_thesis/basis_function_models.html">(online
												extras)</a>
										</p>
									</li>
									<li>
										<p>C. E. Cancino Chacón (2014), <br>
											<strong>&ldquo;Tarkus Belief Propagation: On Message Passing Algorithms and
												Computational Commutative Algebra&rdquo;. </strong><strong>
											</strong><br>
											Graz University of Technology. Graz, Austria. <a
												href="documents/thesis/Cancino-TUGRAZ-2014.pdf">(pdf)</a>
										</p>
									</li>
									<li>
										<p>C. E. Cancino Chacón (2011), <br>
											<strong>&ldquo;Análisis teórico experimental de transductores de ultrasonido
												tipo Langevin&rdquo;. </strong><br>
											National Autonomous University of Mexico. Mexico City, Mexico. <a
												href="documents/thesis/Cancino-UNAM-2011.pdf">(pdf)</a>
										</p>
									</li>
								</ul>
							</div>
						</div>

						<h4 data-appear-animation="fadeInLeft">TECHNICAL REPORTS</h4>
						<div class="row">
							<div class="col-sm-11">
								<ul>
									<li>
										<p>C. E. Cancino Chacón, M. Grachten (2016) <br>
											<strong>&ldquo;Rendering Expressive Performances of Musical Pieces Through
												Sampling From Generative Probabilistic Models&rdquo;</strong><strong>
											</strong><br>
											Technical Report, Austrian Research Institute for Artificial Intelligence,
											Vienna, TR-2016-01. <a
												href="documents/tech_reports/CancinoEtAl-OFAI-TR-2016-01.pdf">(pdf)</a>
										</p>
									</li>
									<li>
										<p>M. Grachten, C. E. Cancino Chacón (2015). <br>
											<strong>&ldquo;</strong><strong>Strategies for Conceptual Change in
												Convolutional Neural Networks&rdquo;</strong><strong>. </strong><br>
											Technical Report, Austrian Research Institute for Artificial Intelligence,
											Vienna, TR-2015-04. <a
												href="documents/tech_reports/GrachtenEtAl-OFAI-TR-2015-04.pdf">(pdf)</a>
										</p>
									</li>
									<li>
										<p>C. E. Cancino Chacón, M. Grachten, G. Widmer (2014), <br>
											<strong>&ldquo;Bayesian Linear Models with Gaussian Priors for Musical
												Expression&rdquo;, </strong><strong> </strong><br>
											Technical Report, Austrian Research Institute for Artificial Intelligence,
											Vienna, TR-2014-12. <a
												href="documents/tech_reports/CancinoEtAl-OFAI-TR-2014-12.pdf">(pdf)</a>
										</p>
									</li>
									<li>
										<p>C. E. Cancino Chacón (2013), <br>
											<strong>&ldquo;Reduced Precision Bayesian Network
												Classifiers&rdquo;</strong><strong>, </strong><br>
											Laboratory for Signal Processing and Speech Communication, Graz University
											of Technology. Graz, Austria. <a
												href="documents/tech_reports/Cancino-SPSC-2013.pdf">(pdf)</a>
										</p>
									</li>
								</ul>
							</div>
						</div>



					</div>




				</div>

				<!-- <hr class="tall" id="music1" /> -->
				<!-- <div class="row"> -->
				<!-- <div class="col-md-9"> -->
				<!-- <h3 data-appear-animation="fadeInLeft"><strong>Music</strong></h3> -->
				<br>
				<!-- <a href="https://soundcloud.com/carlos-eduardo-cancino-chac-n" target="_blank"> https://soundcloud.com/carlos-eduardo-cancino-chac-n</a> -->
				<!-- I took composition lessons with the late Armando Luna Ponce  -->
				<br><br>


				<!-- <iframe width="100%" height="450" scrolling="no" frameborder="no"
							src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/users/29099391&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;visual=true"></iframe>
 -->

			</div>
		</div>
	</div>

	</div>







	<!-- Google Maps -->



	</div>

	<footer class="short" id="footer">

		<div class="footer-copyright">
			<div class="container">
				<div class="row">
					<div class="col-md-2">

					</div>

				</div>
			</div>
		</div>
	</footer>
	</div>

	<!-- Vendor -->
	<script src="vendor/jquery/jquery.js"></script>
	<script src="vendor/jquery.appear/jquery.appear.js"></script>
	<script src="vendor/jquery.easing/jquery.easing.js"></script>
	<script src="vendor/jquery-cookie/jquery-cookie.js"></script>
	<script src="vendor/bootstrap/bootstrap.js"></script>
	<script src="vendor/common/common.js"></script>
	<script src="vendor/jquery.validation/jquery.validation.js"></script>
	<script src="vendor/jquery.stellar/jquery.stellar.js"></script>
	<script src="vendor/jquery.easy-pie-chart/jquery.easy-pie-chart.js"></script>
	<script src="vendor/jquery.gmap/jquery.gmap.js"></script>
	<script src="vendor/isotope/jquery.isotope.js"></script>
	<script src="vendor/owlcarousel/owl.carousel.js"></script>
	<script src="vendor/jflickrfeed/jflickrfeed.js"></script>
	<script src="vendor/magnific-popup/jquery.magnific-popup.js"></script>
	<script src="vendor/vide/vide.js"></script>

	<!-- Theme Base, Components and Settings -->
	<script src="js/theme.js"></script>

	<!-- Specific Page Vendor and Views -->
	<script src="vendor/rs-plugin/js/jquery.themepunch.tools.min.js"></script>
	<script src="vendor/rs-plugin/js/jquery.themepunch.revolution.min.js"></script>
	<script src="vendor/circle-flip-slideshow/js/jquery.flipshow.js"></script>
	<script src="js/views/view.home.js"></script>
	<script src="js/views/view.contact.js"></script>

	<!-- Theme Custom -->
	<script src="js/custom.js"></script>

	<!-- Theme Initialization Files -->
	<script src="js/theme.init.js"></script>

	<!-- Google Analytics: Change UA-XXXXX-X to be your site's ID. Go to http://www.google.com/analytics/ for more information.
	     <script type="text/javascript">
	     
	     var _gaq = _gaq || [];
	     _gaq.push(['_setAccount', 'UA-12345678-1']);
	     _gaq.push(['_trackPageview']);
	     
	     (function() {
	     var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
	     ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
	     var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
	     })();
	     
	     </script>
	-->

	<script src="http://maps.google.com/maps/api/js?sensor=false"></script>
	<script>

		/*
		   Map Settings
   
		   Find the Latitude and Longitude of your address:
		   - http://universimmedia.pagesperso-orange.fr/geo/loc.htm
		   - http://www.findlatitudeandlongitude.com/find-address-from-latitude-and-longitude/
   
		 */

		// Map Markers
		var mapMarkers = [{
			address: "217 Summit Boulevard, Birmingham, AL 35243",
			html: "<strong>Alabama Office</strong><br>217 Summit Boulevard, Birmingham, AL 35243<br><br><a href='#' onclick='mapCenterAt({latitude: 33.44792, longitude: -86.72963, zoom: 16}, event)'>[+] zoom here</a>",
			icon: {
				image: "img/pin.png",
				iconsize: [26, 46],
				iconanchor: [12, 46]
			}
		}, {
			address: "645 E. Shaw Avenue, Fresno, CA 93710",
			html: "<strong>California Office</strong><br>645 E. Shaw Avenue, Fresno, CA 93710<br><br><a href='#' onclick='mapCenterAt({latitude: 36.80948, longitude: -119.77598, zoom: 16}, event)'>[+] zoom here</a>",
			icon: {
				image: "img/pin.png",
				iconsize: [26, 46],
				iconanchor: [12, 46]
			}
		}, {
			address: "New York, NY 10017",
			html: "<strong>New York Office</strong><br>New York, NY 10017<br><br><a href='#' onclick='mapCenterAt({latitude: 40.75198, longitude: -73.96978, zoom: 16}, event)'>[+] zoom here</a>",
			icon: {
				image: "img/pin.png",
				iconsize: [26, 46],
				iconanchor: [12, 46]
			}
		}];

		// Map Initial Location
		var initLatitude = 37.09024;
		var initLongitude = -95.71289;

		// Map Extended Settings
		var mapSettings = {
			controls: {
				panControl: true,
				zoomControl: true,
				mapTypeControl: true,
				scaleControl: true,
				streetViewControl: true,
				overviewMapControl: true
			},
			scrollwheel: false,
			markers: mapMarkers,
			latitude: initLatitude,
			longitude: initLongitude,
			zoom: 5
		};

		var map = $("#googlemaps").gMap(mapSettings);

		// Map Center At
		var mapCenterAt = function (options, e) {
			e.preventDefault();
			$("#googlemaps").gMap("centerAt", options);
		}

	</script>

</body>

</html>